{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "def rename_files_with_offset(dataset_path, output_path):\n",
    "    \"\"\"\n",
    "    Ajoute un offset basé sur le numéro du batch au nom des images et des labels.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): Chemin du dossier contenant les batches.\n",
    "        output_path (str): Chemin du dossier où sauvegarder les fichiers renommés.\n",
    "    \"\"\"\n",
    "    # Créer le dossier de sortie s'il n'existe pas\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Créer les sous-dossiers pour images et labels\n",
    "    images_output_path = os.path.join(output_path, \"images\")\n",
    "    labels_output_path = os.path.join(output_path, \"labels\")\n",
    "    os.makedirs(images_output_path, exist_ok=True)\n",
    "    os.makedirs(labels_output_path, exist_ok=True)\n",
    "\n",
    "    # Récupérer tous les dossiers de batches\n",
    "    batch_paths = sorted(glob.glob(os.path.join(dataset_path, 'batch*')))\n",
    "\n",
    "    # Parcourir chaque batch\n",
    "    for batch_idx, batch_path in enumerate(batch_paths, start=1):\n",
    "        print(f\"Traitement du batch {batch_idx} : {batch_path}\")\n",
    "\n",
    "        # Chemins des dossiers images et labels\n",
    "        images_path = os.path.join(batch_path, \"images\")\n",
    "        labels_path = os.path.join(batch_path, \"labels\")\n",
    "\n",
    "        # Vérifier que les dossiers existent\n",
    "        if not os.path.exists(images_path) or not os.path.exists(labels_path):\n",
    "            print(f\"Dossiers manquants dans {batch_path}, saut du batch.\")\n",
    "            continue\n",
    "\n",
    "        # Traiter les images\n",
    "        image_files = glob.glob(os.path.join(images_path, \"*.jpg\"))\n",
    "        for image_file in image_files:\n",
    "            base_name = os.path.basename(image_file)\n",
    "            # Renommer l'image avec l'offset batch\n",
    "            new_name = f\"batch{batch_idx}_{base_name}\"\n",
    "            new_image_path = os.path.join(images_output_path, new_name)\n",
    "            print(f\"Copie de l'image: {image_file} vers {new_image_path}\")\n",
    "            shutil.copy(image_file, new_image_path)\n",
    "\n",
    "            # Correspondance du fichier de label\n",
    "            label_file = os.path.join(labels_path, base_name.replace(\".jpg\", \".txt\"))\n",
    "            if os.path.exists(label_file):\n",
    "                new_label_name = f\"batch{batch_idx}_{base_name.replace('.jpg', '.txt')}\"\n",
    "                new_label_path = os.path.join(labels_output_path, new_label_name)\n",
    "                print(f\"Copie du label: {label_file} vers {new_label_path}\")\n",
    "                shutil.copy(label_file, new_label_path)\n",
    "            else:\n",
    "                print(f\"Pas de fichier label correspondant pour {image_file}.\")\n",
    "\n",
    "    print(\"Renommage terminé avec succès !\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "dataset_path = \"/kaggle/input/dataset/merged_dataset\"  # Chemin vers votre dataset contenant les batches\n",
    "output_path = \"/kaggle/working/renamed_dataset\"  # Chemin où sauvegarder les fichiers renommés\n",
    "rename_files_with_offset(dataset_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def resize_image_and_update_labels(image_path, label_path, output_image_path, output_label_path, new_size):\n",
    "    # Ouvrir l'image\n",
    "    with Image.open(image_path) as img:\n",
    "        # Obtenir les dimensions originales\n",
    "        original_width, original_height = img.size\n",
    "\n",
    "        # Redimensionner l'image\n",
    "        img_resized = img.resize(new_size)\n",
    "        img_resized.save(output_image_path)\n",
    "\n",
    "        # Ouvrir le fichier d'annotation\n",
    "        with open(label_path, 'r') as label_file:\n",
    "            lines = label_file.readlines()\n",
    "\n",
    "        # Calculer les facteurs de redimensionnement\n",
    "        width_ratio = new_size[0] / original_width\n",
    "        height_ratio = new_size[1] / original_height\n",
    "\n",
    "        # Mettre à jour les annotations\n",
    "        with open(output_label_path, 'w') as label_file:\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                class_id = parts[0]\n",
    "                x_center = float(parts[1]) * original_width\n",
    "                y_center = float(parts[2]) * original_height\n",
    "                width = float(parts[3]) * original_width\n",
    "                height = float(parts[4]) * original_height\n",
    "\n",
    "                # Appliquer le redimensionnement\n",
    "                x_center_resized = x_center * width_ratio\n",
    "                y_center_resized = y_center * height_ratio\n",
    "                width_resized = width * width_ratio\n",
    "                height_resized = height * height_ratio\n",
    "\n",
    "                # Normaliser les nouvelles coordonnées\n",
    "                x_center_normalized = x_center_resized / new_size[0]\n",
    "                y_center_normalized = y_center_resized / new_size[1]\n",
    "                width_normalized = width_resized / new_size[0]\n",
    "                height_normalized = height_resized / new_size[1]\n",
    "\n",
    "                # Écrire la nouvelle annotation\n",
    "                label_file.write(f\"{class_id} {x_center_normalized} {y_center_normalized} {width_normalized} {height_normalized}\\n\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "image_dir = '/kaggle/working/renamed_dataset/images'\n",
    "label_dir = '/kaggle/working//renamed_dataset/labels'\n",
    "output_image_dir = '/kaggle/working/resized_dataset/images_resized'\n",
    "output_label_dir = '/kaggle/working/resized_dataset/labels_resized'\n",
    "new_size = (640, 640)  # Nouvelle taille souhaitée\n",
    "\n",
    "# Créer les répertoires de sortie s'ils n'existent pas\n",
    "os.makedirs(output_image_dir, exist_ok=True)\n",
    "os.makedirs(output_label_dir, exist_ok=True)\n",
    "\n",
    "# Parcourir les images et leurs annotations\n",
    "for image_name in os.listdir(image_dir):\n",
    "    if image_name.endswith(('.jpg', '.png')):\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        label_name = os.path.splitext(image_name)[0] + '.txt'\n",
    "        label_path = os.path.join(label_dir, label_name)\n",
    "\n",
    "        output_image_path = os.path.join(output_image_dir, image_name)\n",
    "        output_label_path = os.path.join(output_label_dir, label_name)\n",
    "\n",
    "        resize_image_and_update_labels(image_path, label_path, output_image_path, output_label_path, new_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def split_data(images_path, labels_path, output_path, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Split data into train and test sets from separate image and label directories.\n",
    "\n",
    "    :param images_path: Path to the folder containing images.\n",
    "    :param labels_path: Path to the folder containing labels.\n",
    "    :param output_path: Path to the output folder where train and test splits will be saved.\n",
    "    :param train_ratio: Ratio of data to include in the train set (default 0.8).\n",
    "    \"\"\"\n",
    "    # Create main output directory\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Define output directories for train and test\n",
    "    train_images_path = os.path.join(output_path, \"train/images\")\n",
    "    train_labels_path = os.path.join(output_path, \"train/labels\")\n",
    "    test_images_path = os.path.join(output_path, \"test/images\")\n",
    "    test_labels_path = os.path.join(output_path, \"test/labels\")\n",
    "\n",
    "    for path in [train_images_path, train_labels_path, test_images_path, test_labels_path]:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # Get list of all image and label files\n",
    "    images = sorted(os.listdir(images_path))\n",
    "    labels = sorted(os.listdir(labels_path))\n",
    "\n",
    "    # Ensure images and labels are aligned\n",
    "    if len(images) != len(labels):\n",
    "        raise ValueError(\"Mismatch between number of images and labels\")\n",
    "\n",
    "    for img, lbl in zip(images, labels):\n",
    "        if os.path.splitext(img)[0] != os.path.splitext(lbl)[0]:\n",
    "            raise ValueError(f\"Mismatch between image {img} and label {lbl}\")\n",
    "\n",
    "    # Shuffle and split data\n",
    "    indices = list(range(len(images)))\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    train_count = int(len(images) * train_ratio)\n",
    "    train_indices = indices[:train_count]\n",
    "    test_indices = indices[train_count:]\n",
    "\n",
    "    # Move files to train and test folders\n",
    "    for i in train_indices:\n",
    "        shutil.copy(os.path.join(images_path, images[i]), train_images_path)\n",
    "        shutil.copy(os.path.join(labels_path, labels[i]), train_labels_path)\n",
    "\n",
    "    for i in test_indices:\n",
    "        shutil.copy(os.path.join(images_path, images[i]), test_images_path)\n",
    "        shutil.copy(os.path.join(labels_path, labels[i]), test_labels_path)\n",
    "\n",
    "    print(f\"Data split completed: {train_count} train, {len(images) - train_count} test\")\n",
    "\n",
    "# Paths\n",
    "images_path = \"/kaggle/working/resized_dataset/images_resized\"\n",
    "labels_path = \"/kaggle/working/resized_dataset/labels_resized\"\n",
    "output_path = \"/kaggle/working/splited_dataset\"\n",
    "\n",
    "# Call the function\n",
    "split_data(images_path, labels_path, output_path, train_ratio=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "import random\n",
    "\n",
    "workingPath = \"/kaggle/working/splited_dataset\"\n",
    "\n",
    "# train and test split based on percentage\n",
    "trainPath = Path(workingPath).joinpath('train/images')\n",
    "trainAllFiles = [str(file) for file in trainPath.glob('*') if str(file).endswith(('.jpg', '.png'))]\n",
    "random.shuffle(trainAllFiles)\n",
    "\n",
    "trainTestSplit = 0.8\n",
    "partitionPoint = int(trainTestSplit * len(trainAllFiles))\n",
    "trainFiles = trainAllFiles[:partitionPoint]\n",
    "validationFiles = trainAllFiles[partitionPoint:]\n",
    "\n",
    "# Save file lists\n",
    "trainFile = Path(workingPath).joinpath('train.txt')\n",
    "valFile = Path(workingPath).joinpath('val.txt')\n",
    "with open(trainFile, \"w\") as train_file:\n",
    "    train_file.write(\"\\n\".join(trainFiles))\n",
    "with open(valFile, \"w\") as val_file:\n",
    "    val_file.write(\"\\n\".join(validationFiles))\n",
    "data = {\n",
    "    'train': str(trainFile),\n",
    "    'val': str(valFile),\n",
    "    'test' : str(Path(workingPath).joinpath('test/images')),\n",
    "    'nc': 60,\n",
    "    'names': {\n",
    "            0: \"Aluminium foil\",\n",
    "            1: \"Battery\",\n",
    "            2: \"Aluminium blister pack\",\n",
    "            3: \"Carded blister pack\",\n",
    "            4: \"Other plastic bottle\",\n",
    "            5: \"Clear plastic bottle\",\n",
    "            6: \"Glass bottle\",\n",
    "            7: \"Plastic bottle cap\",\n",
    "            8: \"Metal bottle cap\",\n",
    "            9: \"Broken glass\",\n",
    "            10: \"Food Can\",\n",
    "            11: \"Aerosol\",\n",
    "            12: \"Drink can\",\n",
    "            13: \"Toilet tube\",\n",
    "            14: \"Other carton\",\n",
    "            15: \"Egg carton\",\n",
    "            16: \"Drink carton\",\n",
    "            17: \"Corrugated carton\",\n",
    "            18: \"Meal carton\",\n",
    "            19: \"Pizza box\",\n",
    "            20: \"Paper cup\",\n",
    "            21: \"Disposable plastic cup\",\n",
    "            22: \"Foam cup\",\n",
    "            23: \"Glass cup\",\n",
    "            24: \"Other plastic cup\",\n",
    "            25: \"Food waste\",\n",
    "            26: \"Glass jar\",\n",
    "            27: \"Plastic lid\",\n",
    "            28: \"Metal lid\",\n",
    "            29: \"Other plastic\",\n",
    "            30: \"Magazine paper\",\n",
    "            31: \"Tissues\",\n",
    "            32: \"Wrapping paper\",\n",
    "            33: \"Normal paper\",\n",
    "            34: \"Paper bag\",\n",
    "            35: \"Plastified paper bag\",\n",
    "            36: \"Plastic film\",\n",
    "            37: \"Six pack rings\",\n",
    "            38: \"Garbage bag\",\n",
    "            39: \"Other plastic wrapper\",\n",
    "            40: \"Single-use carrier bag\",\n",
    "            41: \"Polypropylene bag\",\n",
    "            42: \"Crisp packet\",\n",
    "            43: \"Spread tub\",\n",
    "            44: \"Tupperware\",\n",
    "            45: \"Disposable food container\",\n",
    "            46: \"Foam food container\",\n",
    "            47: \"Other plastic container\",\n",
    "            48: \"Plastic gloves\",\n",
    "            49: \"Plastic utensils\",\n",
    "            50: \"Pop tab\",\n",
    "            51: \"Rope & strings\",\n",
    "            52: \"Scrap metal\",\n",
    "            53: \"Shoe\",\n",
    "            54: \"Squeezable tube\",\n",
    "            55: \"Plastic straw\",\n",
    "            56: \"Paper straw\",\n",
    "            57: \"Styrofoam piece\",\n",
    "            58: \"Unlabeled litter\",\n",
    "            59: \"Cigarette\"\n",
    "        }\n",
    "}\n",
    "\n",
    "\n",
    "# dump yaml file\n",
    "yaml_output_path = Path(workingPath).joinpath('data.yaml')\n",
    "with open(yaml_output_path, \"w\") as f:\n",
    "    yaml.dump(data, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')  # You can replace 'yolov8n.pt' with other variants like 'yolov8s.pt'\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=yaml_output_path,      # Path to the YAML configuration file\n",
    "    epochs=50,                # Number of epochs\n",
    "    batch=16,                 # Batch size\n",
    "    project='YOLOv8_Training',  # Project name\n",
    "    name='trash_detection',  # Name for this training run\n",
    "    save_period=1\n",
    ")\n",
    "\n",
    "# Save the best-trained model\n",
    "trained_model_path = 'YOLOv8_Training/trash_detection/best.pt'\n",
    "print(f\"Training completed! Trained model saved at: {trained_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Charger le modèle entraîné avec le fichier 'best.pt'\n",
    "model = YOLO('YOLOv8_Training/trash_detection/weights/best.pt')\n",
    "\n",
    "# Tester sur une image\n",
    "results = model.predict(source='/kaggle/working/splited_dataset/test/images')  # Remplacez par le chemin réel de l'image\n",
    "\n",
    "# Afficher les résultats\n",
    "for result in results:\n",
    "    result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('YOLOv8_Training/trash_detection/weights/best.pt')\n",
    "model.export(format=\"onnx\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
